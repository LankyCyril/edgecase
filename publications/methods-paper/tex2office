#!/usr/bin/env python
from sys import stderr
from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter
from contextlib import contextmanager
from tempfile import TemporaryDirectory
from os import path, mkdir, walk
from subprocess import call, check_output
from re import search, sub, IGNORECASE
from bs4 import BeautifulSoup, Comment
from itertools import chain
from base64 import b64encode

# Example: ./tex2office -i references.bib figures tables paper.tex
# TODO: formatting of tables
# TODO: quality of converted PNGs (SVGs are fine)


BIBREGEX = r'bibliography|bibtex|biblatex|addbibresource'
SCALE_MAGIC = 1.32
PXFONTS = "\\usepackage{pxfonts}"
BASE64_PREFIXES = {
    "png": "png", "jpg": "jpeg", "jpeg": "jpeg", "svg": "svg+xml"
}


ARG_RULES = {
    ("tex",): dict(help="name of input LaTeX file"),
    ("-i", "--include",): dict(
        help="files and directories to include", nargs="+", metavar="I",
    ),
    ("-t", "--to",): dict(
        help="output format", metavar="T", default="odt",
    ),
    ("--svg",): dict(
        help="convert PDF files to SVG instead of PNG", action="store_true",
    ),
    ("--print-area-width", "--paw",): dict(
        help="width of 'text' in inches (page without margins)", metavar="w",
        type=float, default=5.5
    ),
    ("--print-area-height", "--pah",): dict(
        help="height of 'text' in inches (page without margins)", metavar="h",
        type=float, default=8
    ),
    ("--max-figure-width", "--mw",): dict(
        help="maximum width of figures in percent of print area width",
        metavar="W", type=float, default=100,
    ),
    ("--max-figure-height", "--mh",): dict(
        help="maximum height of figures in percent of print area height",
        metavar="H", type=float, default=80,
    ),
    ("--scale-factor",): dict(
        help="scale factor for raster figures (some magic here)", metavar="S",
        type=float, default=SCALE_MAGIC,
    ),
    ("--replace-fonts", "--rf",): dict(
        help="lines to replace with {}".format(PXFONTS), nargs="+",
        metavar="P", default="\\usepackage[sfdefault]{roboto}"
    ),
    ("-d", "--debug",): dict(help="debug mode", action="store_true"),
}


def WideHelpFormatter(prog):
    """Formatter class for ArgumentParser with wider fields than default"""
    return ArgumentDefaultsHelpFormatter(prog, max_help_position=48, width=150)


@contextmanager
def Subdirectory(dirname="tmp_tex2office"):
    """Drop-in replacement for TemporaryDirectory that creates a statically named subdirectory in current $PWD"""
    if path.isdir(dirname):
        yield dirname
    elif path.exists(dirname):
        raise OSError("{} exists but is not a directory".format(dirname))
    else:
        mkdir(dirname)
        yield dirname


def parse_and_validate_args(parser):
    """Invokes argparse.ArgumentParser.parse(), interprets and validates arguments with project-specific logic"""
    args = parser.parse_args()
    if args.debug:
        TempDir = Subdirectory
    else:
        TempDir = TemporaryDirectory
    if args.to not in {"odt", "docx"}:
        raise NotImplementedError("Output format: " + args.to)
    if args.include is not None:
        if not isinstance(args.include, list):
            args.include = [args.include]
    if args.replace_fonts is not None:
        if not isinstance(args.replace_fonts, list):
            args.replace_fonts = [args.replace_fonts]
    return args, TempDir


def prepare_source(tex, workdir, replace_fonts, debug, basename="source"):
    """Creates a copy of the source LaTeX file and modifies it for improved compatibility"""
    with open(tex, mode="rt") as tex_in:
        with open(path.join(workdir, basename+".tex"), mode="wt") as tex_out:
            for line in map(str.strip, tex_in):
                if line in replace_fonts:
                    line = PXFONTS
                elif search(r'^\s*\\\\%rem\s*$', line):
                    continue
                elif search(r'\\\\%rem', line):
                    line = sub(r'\\\\%rem', " ", line)
                line = sub(r'\\textcolor{white}\S*', "", line)
                print(line, file=tex_out)
    return basename


def mklink(filename, workdir):
    """Creates symlinks in the working directory"""
    target = path.join(workdir, filename)
    if path.exists(target):
        if not path.islink(target):
            raise OSError("{} exists but is not a symlink".format(target))
    else:
        ln_command = [
            "ln", "-sf", path.realpath(filename), path.join(workdir, filename)
        ]
        print(*ln_command, file=stderr)
        call(ln_command)


def has_bibliography(basename, include, workdir):
    """Checks if a bibtex pass is required"""
    if any((path.isfile(f) and f.endswith(".bib")) for f in include):
        return True
    else:
        for nodename in include:
            if path.isdir(nodename):
                for _, _, filename in walk(nodename):
                    if filename.endswith(".bib"):
                        return True
    with open(path.join(workdir, basename+".tex"), mode="rt") as tex:
        for line in tex:
            if search(BIBREGEX, line, flags=IGNORECASE):
                return True
    return False


def xhlatex(basename, include, workdir, debug):
    """Runs xhlatex and bibtex (if necessary) on the source file with an appropriate number of passes"""
    if (not debug) or (not path.exists(path.join(workdir, basename+".html"))):
        call(["xhlatex", basename], cwd=workdir)
        if has_bibliography(basename, include, workdir):
            call(["bibtex", basename], cwd=workdir)
            call(["xhlatex", basename], cwd=workdir)


def simplify_html(basename, workdir, debug):
    """Strips comment tags and simplifies HTML formatting"""
    with open(path.join(workdir, basename+".html"), mode="rb") as html:
        soup = BeautifulSoup(html, "html.parser")
    iter_unwanted_tags = chain(
        soup.find_all(text=lambda t: isinstance(t, Comment)),
        soup.find_all("hr"),
        soup.find_all("dt"), # to be replaced with <li>s
    )
    for unwanted_tag in iter_unwanted_tags:
        unwanted_tag.extract()
    for tag in soup.find_all("sup"):
        tag.attrs = {} # remove class="textsuperscript", only ruins things
        tag.string = tag.string # remove nested spans in superscripts
    return soup


def is_newly_generated(img):
    """Check if the image is a newly-generated bitmap (such as an equation)"""
    return img["src"].startswith("source") and (img["alt"] != "PIC")


def to_base64(soup, workdir, debug):
    """Convert newly generated bitmaps (such as equations) and original PNGs to base64 rasters"""
    for img in soup.find_all("img"):
        extension = img["src"].split(".")[-1].lower()
        if extension in BASE64_PREFIXES:
            with open(path.join(workdir, img["src"]), mode="rb") as img_bytes:
                b64 = b64encode(img_bytes.read())
            img["src"] = "data:image/{};base64,{}".format(
                BASE64_PREFIXES[extension], b64.decode(),
            )
        else:
            warning_mask = "Extension not recognized, leaving as-is: {}"
            print(warning_mask.format(img["src"]), file=stderr)
    return soup


def get_original_pdf_name(src):
    """Find the PDF file that the current PNG originated from"""
    pdf = sub(r'-\.png$', ".pdf", src)
    if path.isfile(pdf):
        return pdf
    else:
        print("Could not find original PDF for: " + src, file=stderr)
        return None


def make_svg(pdf, debug):
    """Convert PDF to SVG with Inkscape (inkscape)"""
    svg = sub(r'\.pdf', ".svg", pdf)
    if (not debug) or (not path.isfile(svg)):
        inkscape_command = ["inkscape", "-z", "-f", pdf, "-D", "-l", svg]
        print(*inkscape_command, file=stderr)
        call(inkscape_command)
    return svg


def get_original_image_dimensions(src):
    """Measure width and height of image with ImageMagick (identify)"""
    identify_command = ["identify", src]
    print(*identify_command, file=stderr)
    identify_output = check_output(identify_command).decode()
    identify_fields = identify_output.split()
    if len(identify_fields) > 2:
        dimension_fields = identify_fields[2].split("x")
        if len(dimension_fields) == 2:
            real_width, real_height = (
                float(dimension_fields[0]),
                float(dimension_fields[1]),
            )
        else:
            return None, None
    else:
        return None, None
    if (real_width == 0) or (real_height == 0):
        return None, None
    else:
        return real_width, real_height


def adjust_image_dimensions(src, print_area_width, print_area_height, max_figure_width, max_figure_height, scale_factor):
    """Scale image to fit a max_figure_width x max_figure_height box"""
    print_area_aspect = print_area_width / print_area_height
    max_figure_aspect = print_area_aspect * max_figure_width / max_figure_height
    real_width, real_height = get_original_image_dimensions(src)
    if (real_width is None) or (real_height is None):
        print("Could not determine size, leaving as-is: " + src, file=stderr)
        return None
    else:
        if real_width / real_height >= max_figure_aspect:
            # the image is "more horizontal" than the box:
            width = print_area_width * max_figure_width / 100
            height = width * real_height / real_width
        else: # the image is "more vertical" than the box:
            height = print_area_height * max_figure_height / 100
            width = height * real_width / real_height
        return "width: {:.3}in; height: {:.3}in".format(
            width * scale_factor, height * scale_factor,
        )


def adjust_PICs(soup, workdir, request_svg, print_area_width, print_area_height, max_figure_width, max_figure_height, scale_factor, debug):
    """Adjust sizes of figures; if request_svg==True, also convert preexisting PDFs to SVGs and replace auto-generated PNGs"""
    for img in soup.find_all("img"):
        if not is_newly_generated(img):
            if request_svg:
                pdf = get_original_pdf_name(img["src"])
                if pdf:
                    img["src"] = make_svg(pdf, debug)
            style = adjust_image_dimensions(
                img["src"], print_area_width, print_area_height,
                max_figure_width, max_figure_height, scale_factor,
            )
            if style:
                img["style"] = style
    return soup


def fix_bib(html_in, html_out):
    with open(html_in, mode="rt") as mess:
        with open(html_out, mode="wt") as nomess:
            for line in map(str.strip, mess):
                line = sub(r'<dl', "<ol", line)
                line = sub(r'</dl', "</ol", line)
                line = sub(r'</dl', "</ol", line)
                line = sub(r'<dd', "<li", line)
                line = sub(r'</dd', "</li", line)
                print(line, file=nomess)


def soffice_convert(workdir, to, debug, prefix):
    """Convert soup to ODT/DOCX with LibreOffice (soffice)"""
    if to == "odt":
        soffice_command = [
            "soffice", "--headless", "--convert-to",
            "odt:writerweb8_writer", prefix+".html",
        ]
    elif to == "docx":
        soffice_command = [
            "soffice", "--headless", "--convert-to",
            'docx:"MS Word 2007 XML"', prefix+".html",
        ]
    else:
        raise NotImplementedError("Output format: " + to)
    print(*soffice_command, file=stderr)
    call(soffice_command, cwd=workdir)
    return prefix + "." + to


def main(args, TempDir, prefix="converted"):
    """Dispatches data and arguments to subroutines"""
    with TempDir() as workdir:
        basename = prepare_source(
            args.tex, workdir, args.replace_fonts, args.debug
        )
        if args.include:
            for filename in args.include:
                mklink(filename, workdir)
        xhlatex(basename, args.include, workdir, args.debug)
        soup = simplify_html(basename, workdir, args.debug)
        soup_with_PIC_fix = adjust_PICs(
            soup, workdir, args.svg,
            args.print_area_width, args.print_area_height,
            args.max_figure_width, args.max_figure_height,
            args.scale_factor, args.debug,
        )
        soup_with_base64 = to_base64(
            soup_with_PIC_fix, workdir, args.debug,
        )
        html_with_messy_bib = path.join(workdir, "messy-"+prefix+".html")
        with open(html_with_messy_bib, mode="wt") as html:
            print(soup_with_base64, file=html)
        fix_bib(
            path.join(workdir, "messy-"+prefix+".html"),
            path.join(workdir, prefix+".html"),
        )
        document = soffice_convert(workdir, args.to, args.debug, prefix=prefix)
        final_document = sub(r'\.tex', "", args.tex) + "." + args.to
        call(["cp", path.join(workdir, document), final_document])
    return 0


if __name__ == "__main__":
    # parse arguments and feed them to main():
    parser = ArgumentParser(prog=__file__, formatter_class=WideHelpFormatter)
    for arg_names, arg_params in ARG_RULES.items():
        parser.add_argument(*arg_names, **arg_params)
    args, TempDir = parse_and_validate_args(parser)
    returncode = main(args, TempDir)
    exit(returncode)
